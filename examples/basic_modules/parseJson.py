import os
import json
import psycopg2
import sys

# Add the parent directory to the path to allow imports
src_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'src'))
sys.path.insert(0, src_path)

# from polardb_export_insert_1 import insert_data
from batchImport_polardbFromJson import insert_data, update_graph

DB_CONFIG = {
    'host': 'xxxxx',
    'port': 5432,
    'database': 'xxxx',
    'user': 'xxxx',
    'password': 'xxxxx'
}
conn = psycopg2.connect(**DB_CONFIG)

def insert(batch):
    """
    æ¨¡æ‹Ÿæ’å…¥å‡½æ•°ã€‚
    è¿™é‡Œä½ å¯ä»¥æ›¿æ¢æˆå®é™…æ•°æ®åº“æˆ–APIè°ƒç”¨é€»è¾‘ã€‚
    """
    print(f"âœ… è°ƒç”¨ insert() æ’å…¥ {len(batch)} æ¡è®°å½•")
    insert_data(conn, batch)
    # ç¤ºä¾‹ï¼šä½ çš„æ•°æ®åº“æ’å…¥é€»è¾‘å†™åœ¨è¿™é‡Œ
    # db.insert_many(batch)


def process_folder(folder_path, batch_size=1000):
    """
    éå†æ–‡ä»¶å¤¹ï¼ŒæŒ‰ batch_size åˆ†æ‰¹è§£æ JSON å¹¶è°ƒç”¨ insertã€‚
    """
    batch = []
    total_count = 0

    for root, dirs, files in os.walk(folder_path):
        for file in files:
            # Only process .json files
            if not file.endswith('.json'):
                continue
                
            file_path = os.path.join(root, file)
            print(f"ğŸ“„ æ­£åœ¨è¯»å–æ–‡ä»¶: {file_path}")

            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            obj = json.loads(line)
                            # ç¡®ä¿è§£æå‡ºçš„å¯¹è±¡æ˜¯å­—å…¸ç±»å‹ï¼Œå¹¶ä¸”åŒ…å«å¿…è¦çš„å­—æ®µ
                            if isinstance(obj, dict) and "id" in obj and "memory" in obj:
                                batch.append(obj)
                                total_count += 1

                                # æ¯æ»¡ batch_size æ¡ï¼Œè°ƒç”¨ insert å¹¶æ¸…ç©ºç¼“å­˜
                                if len(batch) >= batch_size:
                                    insert(batch)
                                    batch = []  # æ¸…ç©º
                            else:
                                print(f"âš ï¸ è·³è¿‡æ— æ•ˆå¯¹è±¡ï¼ˆç¼ºå°‘å¿…è¦å­—æ®µï¼‰: {line[:80]}...")
                        except json.JSONDecodeError:
                            print(f"âš ï¸ è·³è¿‡æ— æ•ˆ JSON: {line[:80]}...")
            except (UnicodeDecodeError, IOError) as e:
                print(f"âš ï¸ è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶ {file_path}: {e}")
                continue

    # å¤„ç†æœ€åä¸è¶³ batch_size çš„éƒ¨åˆ†
    if batch:
        insert(batch)
        update_graph()

    print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼Œå…±å¤„ç† {total_count} æ¡è®°å½•ã€‚")


if __name__ == "__main__":
    # folder_path = r"/Users/ccl/Desktop/file/export13/ceshi"
    # 10W
    folder_path = r"/Users/ccl/Desktop/file/export15/Memory"
    # 70W
    folder_path = r"/Users/ccl/Desktop/file/export13/Memory"
    process_folder(folder_path, batch_size=1000)
