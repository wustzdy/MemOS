import json
import shutil
import sys
import uuid

from pathlib import Path

from transformers import DynamicCache

from memos.configs.mem_cube import GeneralMemCubeConfig
from memos.configs.mem_os import MOSConfig
from memos.configs.memory import MemoryConfigFactory
from memos.mem_cube.general import GeneralMemCube
from memos.mem_os.main import MOS
from memos.mem_scheduler.schemas.message_schemas import ScheduleMessageItem
from memos.mem_scheduler.schemas.task_schemas import (
    ANSWER_TASK_LABEL,
    MEM_UPDATE_TASK_LABEL,
    QUERY_TASK_LABEL,
)
from memos.mem_scheduler.utils.db_utils import get_utc_now
from memos.mem_scheduler.utils.misc_utils import parse_yaml
from memos.memories.activation.item import KVCacheItem
from memos.memories.factory import MemoryFactory


FILE_PATH = Path(__file__).absolute()
BASE_DIR = FILE_PATH.parent.parent.parent
sys.path.insert(0, str(BASE_DIR))  # Enable execution from any working directory


def get_cache_info(cache):
    if not cache:
        return None

    num_layers = 0
    total_size_bytes = 0

    if hasattr(cache, "layers"):
        num_layers = len(cache.layers)
        for layer in cache.layers:
            if hasattr(layer, "key_cache") and layer.key_cache is not None:
                total_size_bytes += layer.key_cache.nelement() * layer.key_cache.element_size()
            if hasattr(layer, "value_cache") and layer.value_cache is not None:
                total_size_bytes += layer.value_cache.nelement() * layer.value_cache.element_size()

            if hasattr(layer, "keys") and layer.keys is not None:
                total_size_bytes += layer.keys.nelement() * layer.keys.element_size()
            if hasattr(layer, "values") and layer.values is not None:
                total_size_bytes += layer.values.nelement() * layer.values.element_size()

    elif hasattr(cache, "key_cache") and hasattr(cache, "value_cache"):
        num_layers = len(cache.key_cache)
        for k, v in zip(cache.key_cache, cache.value_cache, strict=False):
            if k is not None:
                total_size_bytes += k.nelement() * k.element_size()
            if v is not None:
                total_size_bytes += v.nelement() * v.element_size()

    return {
        "num_layers": num_layers,
        "size_bytes": total_size_bytes,
        "size_mb": f"{total_size_bytes / (1024 * 1024):.2f} MB",
    }


def serialize_item(obj):
    if isinstance(obj, list):
        return [serialize_item(x) for x in obj]

    if isinstance(obj, KVCacheItem):
        return {
            "id": obj.id,
            "metadata": obj.metadata,
            "records": obj.records.model_dump()
            if hasattr(obj.records, "model_dump")
            else obj.records,
            "memory": get_cache_info(obj.memory),
        }

    if isinstance(obj, DynamicCache):
        return get_cache_info(obj)

    return str(obj)


def kv_cache_only():
    # ä¸º KVCacheMemory(HuggingFace åç«¯)åˆ›å»ºé…ç½®
    config = MemoryConfigFactory(
        backend="kv_cache",
        config={
            "extractor_llm": {
                "backend": "huggingface",
                "config": {
                    "model_name_or_path": "Qwen/Qwen3-0.6B",
                    "max_tokens": 32,
                    "add_generation_prompt": True,
                    "remove_think_prefix": True,
                },
            },
        },
    )

    # å®ä¾‹åŒ– KVCacheMemory
    kv_mem = MemoryFactory.from_config(config)

    # æå–ä¸€ä¸ª KVCacheItem(DynamicCache)
    prompt = [
        {"role": "user", "content": "What is MemOS?"},
        {"role": "assistant", "content": "MemOS is a memory operating system for LLMs."},
    ]
    print("===== Extract KVCacheItem =====")
    cache_item = kv_mem.extract(prompt)
    print(json.dumps(serialize_item(cache_item), indent=2, default=str))

    # å°†ç¼“å­˜æ·»åŠ åˆ°å†…å­˜ä¸­
    kv_mem.add([cache_item])
    print("All caches:")
    print(json.dumps(serialize_item(kv_mem.get_all()), indent=2, default=str))

    # é€šè¿‡ ID è·å–
    retrieved = kv_mem.get(cache_item.id)
    print("Retrieved:")
    print(json.dumps(serialize_item(retrieved), indent=2, default=str))

    # åˆå¹¶ç¼“å­˜
    item2 = kv_mem.extract([{"role": "user", "content": "Tell me a joke."}])
    kv_mem.add([item2])
    merged = kv_mem.get_cache([cache_item.id, item2.id])
    print("Merged cache:")
    print(json.dumps(serialize_item(merged), indent=2, default=str))

    # åˆ é™¤å…¶ä¸­ä¸€ä¸ª
    kv_mem.delete([cache_item.id])
    print("After delete:")
    print(json.dumps(serialize_item(kv_mem.get_all()), indent=2, default=str))

    # å¯¼å‡ºå’ŒåŠ è½½ç¼“å­˜
    kv_mem.dump("tmp/kv_mem")
    print("Dumped to tmp/kv_mem")
    kv_mem.delete_all()
    kv_mem.load("tmp/kv_mem")
    print("Loaded caches:")
    print(json.dumps(serialize_item(kv_mem.get_all()), indent=2, default=str))


def run_scheduler_example():
    # ä½¿ç”¨ MemScheduler åŠ è½½ä¸» MOS(Memory-Oriented System)é…ç½®æ–‡ä»¶
    config = parse_yaml("./examples/data/config/mem_scheduler/memos_config_w_scheduler.yaml")
    # å°†è§£æå‡ºçš„é…ç½®å­—å…¸ä¼ å…¥ MOSConfig æ„é€ å™¨, æ„å»ºé…ç½®å¯¹è±¡
    mos_config = MOSConfig(**config)
    # ä½¿ç”¨é…ç½®å¯¹è±¡åˆå§‹åŒ– MOS ç³»ç»Ÿå®ä¾‹
    mos = MOS(mos_config)

    # ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„åŠ¨æ€ç”¨æˆ· ID(ä½¿ç”¨ UUID4)
    user_id = str(uuid.uuid4())
    # åœ¨ MOS ç³»ç»Ÿä¸­ä¸ºè¯¥ç”¨æˆ·åˆ›å»ºè´¦æˆ·
    mos.create_user(user_id=user_id)

    # ä» YAML æ–‡ä»¶åŠ è½½ MemCube(è®°å¿†ç«‹æ–¹ä½“)çš„é€šç”¨é…ç½®
    config = GeneralMemCubeConfig.from_yaml_file(
        "./examples/data/config/mem_scheduler/mem_cube_config.yaml"
    )
    # å®šä¹‰ MemCube çš„å”¯ä¸€æ ‡è¯†ç¬¦
    mem_cube_id = "mem_cube_5"
    # å®šä¹‰ MemCube çš„æœ¬åœ°å­˜å‚¨è·¯å¾„(è·¯å¾„ä¸­åŒ…å«ç”¨æˆ· ID å’Œ MemCube ID)
    mem_cube_name_or_path = f"./outputs/mem_scheduler/{user_id}/{mem_cube_id}"

    # å¦‚æœè¯¥è·¯å¾„å·²å­˜åœ¨, åˆ™å…ˆåˆ é™¤æ—§ç›®å½•
    if Path(mem_cube_name_or_path).exists():
        shutil.rmtree(mem_cube_name_or_path)
        print(f"{mem_cube_name_or_path} ç›®å½•éç©ºï¼Œå·²è¢«åˆ é™¤ã€‚")

    # æ ¹æ®åŠ è½½çš„é…ç½®åˆ›å»ºä¸€ä¸ªæ–°çš„ MemCube å®ä¾‹
    mem_cube = GeneralMemCube(config)
    # å°†è¯¥ MemCube å®ä¾‹åºåˆ—åŒ–å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    mem_cube.dump(mem_cube_name_or_path)

    # åœ¨ MOS ç³»ç»Ÿä¸­ä¸ºå½“å‰ç”¨æˆ·æ³¨å†Œè¿™ä¸ª MemCube
    mos.register_mem_cube(
        mem_cube_name_or_path=mem_cube_name_or_path, mem_cube_id=mem_cube_id, user_id=user_id
    )

    # å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°, ç”¨äºè·å–ç¼“å­˜(å¦‚ KV Cache)çš„å†…å­˜ä¿¡æ¯
    def get_cache_info(cache):
        # å¦‚æœç¼“å­˜ä¸ºç©º, åˆ™ç›´æ¥è¿”å› None
        if not cache:
            return None

        num_layers = 0  # è®°å½•ç¼“å­˜çš„å±‚æ•°
        total_size_bytes = 0  # è®°å½•æ€»å­—èŠ‚æ•°

        # æƒ…å†µä¸€: ç¼“å­˜ç»“æ„åŒ…å« layers å±æ€§(å¦‚ HuggingFace çš„ç¼“å­˜æ ¼å¼)
        if hasattr(cache, "layers"):
            num_layers = len(cache.layers)
            for layer in cache.layers:
                # ç»Ÿè®¡ key_cache çš„å†…å­˜å ç”¨(å¦‚æœå­˜åœ¨)
                if hasattr(layer, "key_cache") and layer.key_cache is not None:
                    total_size_bytes += layer.key_cache.nelement() * layer.key_cache.element_size()
                # ç»Ÿè®¡ value_cache çš„å†…å­˜å ç”¨(å¦‚æœå­˜åœ¨)
                if hasattr(layer, "value_cache") and layer.value_cache is not None:
                    total_size_bytes += (
                        layer.value_cache.nelement() * layer.value_cache.element_size()
                    )

                # å…¼å®¹å…¶ä»–å¯èƒ½çš„ç¼“å­˜å‘½åæ–¹å¼(å¦‚ keys/values)
                if hasattr(layer, "keys") and layer.keys is not None:
                    total_size_bytes += layer.keys.nelement() * layer.keys.element_size()
                if hasattr(layer, "values") and layer.values is not None:
                    total_size_bytes += layer.values.nelement() * layer.values.element_size()

        # æƒ…å†µäºŒ: ç¼“å­˜ç»“æ„ç›´æ¥åŒ…å« key_cache å’Œ value_cache åˆ—è¡¨(å¦‚æŸäº›è‡ªå®šä¹‰æ ¼å¼)
        elif hasattr(cache, "key_cache") and hasattr(cache, "value_cache"):
            num_layers = len(cache.key_cache)
            for k, v in zip(cache.key_cache, cache.value_cache, strict=False):
                if k is not None:
                    total_size_bytes += k.nelement() * k.element_size()
                if v is not None:
                    total_size_bytes += v.nelement() * v.element_size()

        # è¿”å›ç»“æ„åŒ–çš„ç¼“å­˜ä¿¡æ¯, åŒ…æ‹¬å±‚æ•°, å­—èŠ‚æ•°å’Œä»¥ MB ä¸ºå•ä½çš„å¯è¯»æ ¼å¼
        return {
            "num_layers": num_layers,
            "size_bytes": total_size_bytes,
            "size_mb": f"{total_size_bytes / (1024 * 1024):.2f} MB",
        }

    # å®šä¹‰è‡ªå®šä¹‰çš„æŸ¥è¯¢(query)å¤„ç†å‡½æ•°
    def custom_query_handler(messages: list[ScheduleMessageItem]):
        for msg in messages:
            # æ‰“å°ç”¨æˆ·è¾“å…¥å†…å®¹
            print(f"\n[scheduler] ç”¨æˆ·è¾“å…¥äº†æŸ¥è¯¢ï¼š{msg.content}")
            # æ‰‹åŠ¨æ„é€ ä¸€ä¸ªå¸¦æœ‰ MEM_UPDATE æ ‡ç­¾çš„æ–°æ¶ˆæ¯, ç”¨äºè§¦å‘è®°å¿†æ›´æ–°
            new_msg = msg.model_copy(update={"label": MEM_UPDATE_TASK_LABEL})
            # å°†è¯¥æ¶ˆæ¯æäº¤ç»™è°ƒåº¦å™¨å¤„ç†
            mos.mem_scheduler.submit_messages([new_msg])

    # å®šä¹‰è‡ªå®šä¹‰çš„å›ç­”(answer)å¤„ç†å‡½æ•°
    def custom_answer_handler(messages: list[ScheduleMessageItem]):
        for msg in messages:
            # æ‰“å° LLM çš„å›å¤å†…å®¹
            print(f"\n[scheduler] LLM å›å¤äº†ç­”æ¡ˆï¼š{msg.content}")

    # å®šä¹‰è‡ªå®šä¹‰çš„è®°å¿†æ›´æ–°(mem_update)å¤„ç†å‡½æ•°
    def custom_mem_update_handler(messages: list[ScheduleMessageItem]):
        for msg in messages:
            mem_cube = mos.mem_cubes.get(msg.mem_cube_id)
            kv_mem = mem_cube.act_mem
            # å¦‚æœè¯¥ MemCube é…ç½®äº†æ–‡æœ¬è®°å¿†(TreeTextMemory / NaiveTextMemory)
            if mem_cube and mem_cube.text_mem:
                # åœ¨æ–‡æœ¬è®°å¿†ä¸­æœç´¢ä¸å½“å‰å†…å®¹ç›¸å…³çš„è®°å¿†(è¿”å› top_k=3 æ¡)
                results = mem_cube.text_mem.search(msg.content, top_k=3)
                for mem in results:
                    print(f"\n[scheduler] æ£€ç´¢åˆ°çš„è®°å¿†ï¼š{mem.memory}")
                    print("\n[scheduler] è½¬æ¢ä¸ºæ¿€æ´»è®°å¿†......")
                    # ä»æ–‡æœ¬è®°å¿†ä¸­æå–å¯¹åº”çš„ KV ç¼“å­˜é¡¹
                    cache_item = kv_mem.extract(mem.memory)
                    # é™„åŠ å…ƒä¿¡æ¯
                    cache_item.records.text_memories = [mem.memory]
                    cache_item.records.timestamp = get_utc_now()
                    # å°†è¯¥ç¼“å­˜é¡¹æ·»åŠ åˆ°æ¿€æ´»è®°å¿†ä¸­
                    kv_mem.add([cache_item])
                    print("\n[scheduler] å®Œæˆï¼")

    # å°†ä¸Šè¿°ä¸‰ä¸ªè‡ªå®šä¹‰å¤„ç†å™¨æ³¨å†Œåˆ°è°ƒåº¦å™¨çš„åˆ†å‘å™¨ä¸­, åˆ†åˆ«å¯¹åº”ä¸åŒä»»åŠ¡æ ‡ç­¾
    mos.mem_scheduler.dispatcher.register_handlers(
        {
            QUERY_TASK_LABEL: custom_query_handler,  # æŸ¥è¯¢ä»»åŠ¡
            ANSWER_TASK_LABEL: custom_answer_handler,  # å›ç­”ä»»åŠ¡
            MEM_UPDATE_TASK_LABEL: custom_mem_update_handler,  # è®°å¿†æ›´æ–°ä»»åŠ¡
        }
    )

    # åˆå§‹æ·»åŠ ä¸¤æ¡æµ‹è¯•æ¶ˆæ¯(ç”¨æˆ·å’ŒåŠ©æ‰‹çš„å¯¹è¯)åˆ°ç³»ç»Ÿä¸­
    messages = [
        {"role": "user", "content": "I like playing football."},
        {"role": "assistant", "content": "I like playing football too."},
    ]
    mos.add(messages, user_id=user_id, mem_cube_id=mem_cube_id)

    # è¿›å…¥èŠå¤©å¾ªç¯: å±•ç¤º TreeTextMemory çš„è®°å¿†èŠ‚ç‚¹ç»“æ„ + KV Cache çš„çŠ¶æ€
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥å¹¶å»é™¤é¦–å°¾ç©ºæ ¼
        user_input = input("ğŸ‘¤ [You] ").strip()
        print()
        # è°ƒç”¨ MOS ç³»ç»Ÿè¿›è¡ŒèŠå¤©å“åº”
        response = mos.chat(user_input, user_id=user_id)
        # è·å–è¯¥ç”¨æˆ·å½“å‰ MemCube ä¸­çš„æ‰€æœ‰è®°å¿†å†…å®¹
        retrieved_memories = mos.get_all(mem_cube_id=mem_cube_id, user_id=user_id)

        # æ‰“å°åŠ©æ‰‹çš„å›å¤
        print(f"ğŸ¤– [Assistant] {response}")

        # è·å–æ–‡æœ¬è®°å¿†éƒ¨åˆ† - TreeTextMemory
        memories = retrieved_memories["text_mem"][0]["memories"]
        for mem in memories:
            print(f"[æ–‡æœ¬è®°å¿†] {mem.memory}")

        # è·å–å¯¹åº”çš„ MemCube å’Œå…¶æ¿€æ´»è®°å¿†(KV Cache)
        mem_cube = mos.mem_scheduler.mem_cube
        kv_mem = mem_cube.act_mem
        # éå†æ‰€æœ‰æ¿€æ´»è®°å¿†é¡¹, æ‰“å°å…¶ç¼“å­˜ä¿¡æ¯å’Œè®°å½•
        for cache_item in kv_mem.get_all():
            print(f"[æ¿€æ´»è®°å¿†] {get_cache_info(cache_item.memory)} ï¼ˆè®°å½•ï¼š{cache_item.records}ï¼‰")


if __name__ == "__main__":
    kv_cache_only()

    run_scheduler_example()
